{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Images from WIKIART\n",
    "Scraper of wikiart database for a certain specified amount of photos for given genres. The amount of images downloaded can be controlled in the genres dictionary. This method is up-to-date with respect to url names and image amounts as of June 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains a script that scrapes the wikiart database for a certain specified amount of photos for given genres. The amount of images downloaded can be controlled in the genres dictionary. This method is up-to-date with respect to url names and image amounts as of June 2017.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import bs4\n",
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import multiprocessing\n",
    "\n",
    "# A list of genres hosted on wikiart.org as well as the number of pages to pull images from, numbers were set from manual inspection and are only approximations of how many pages each genre contains\n",
    "genres = [('portrait',250),\n",
    "        ('landscape',250),\n",
    "        ('genre-painting',250),\n",
    "        ('abstract',250),\n",
    "        ('religious-painting',140),\n",
    "        ('cityscape',110),\n",
    "        ('figurative',75),\n",
    "        ('still-life',50),\n",
    "        ('symbolic-painting',50),\n",
    "        ('nude-painting-nu',50),\n",
    "        ('mythological-painting',35),\n",
    "        ('marina',30),\n",
    "        ('flower-painting',30),\n",
    "        ('animal-painting',30)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Access the html of the page given a genre and pagenumber that are used to generate a url, from this html find the urls of all images hosted on the page using page layout as of June 2017, return a list of alls urls to paintings\n",
    "def soupit(j,genre):\n",
    "    try:\n",
    "        url = \"https://www.wikiart.org/en/paintings-by-genre/\"+ genre+ \"/\" + str(j)\n",
    "        html = urllib.request.urlopen(url)\n",
    "        soup =  BeautifulSoup(html)\n",
    "        found = False\n",
    "        urls = []\n",
    "        for i in str(soup.findAll()).split():\n",
    "            if i == 'data':\n",
    "                found = True\n",
    "            if found == True:\n",
    "                if '}];' in i:\n",
    "                    break;\n",
    "                if 'https' in i:\n",
    "                    web = \"http\" + i[6:-2]\n",
    "                    urls.append(web)\n",
    "                    j = j+1\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        print('Failed to find the following genre page combo: '+genre+str(j))\n",
    "\n",
    "\n",
    "#Given a url for an image, we download and save the image while also recovering information about the painting in the saved name depending on the length of the file.split('/') information (which corresponds to how much information is available)\n",
    "\n",
    "def dwnld(web,genre):\n",
    "    i,file = web\n",
    "    name = file.split('/')\n",
    "    savename = ''\n",
    "    if len(name) == 6:\n",
    "        savename = genre+\"/\"+ name[4] + \"+\" + name[5].split('.')[0] +\".jpg\"\n",
    "    if len(name) == 5:\n",
    "        savename = genre+\"/\"+name[4].split('.')[0]+\".jpg\"\n",
    "    if len(name) == 7:\n",
    "        savename = genre+\"/\"+ name[5] + \"+\" + name[6].split('.')[0] +\".jpg\"\n",
    "        \n",
    "    print(genre + str(i))\n",
    "    #If we get an exception in this operation it is probably because there was a nonstandard unicode character in the name of the painting, do some fancy magic to fix this in the exception handling code\n",
    "    try:\n",
    "        urllib.request.urlretrieve(file,savename)\n",
    "    except Exception:\n",
    "        ofile = file\n",
    "        file = urllib.parse.urlsplit(file)\n",
    "        file = list(file)\n",
    "        file[2] = urllib.parse.quote(file[2])\n",
    "        file = urllib.parse.urlunsplit(file)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file,savename)\n",
    "            print('Suceeded on second try for '+ file)\n",
    "        except Exception:\n",
    "            print('We failed on the second try for ' + file)\n",
    "\n",
    "\n",
    "#We can run both the url retrieving code and the image downloading code in parallel, and we set up the logic for that here\n",
    "def for_genre(genre,num):\n",
    "    pool = ThreadPool(multiprocessing.cpu_count()-1)\n",
    "    nums = list(range(1,num))\n",
    "    results = pool.starmap(soupit,zip(nums,itertools.repeat(genre)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    #build up the list of urls with the results of all the sub-processes that succeeded in a single list\n",
    "    new_results = []\n",
    "    for j in results:\n",
    "        if j:\n",
    "            for i in j:\n",
    "                new_results.append(i)\n",
    "    \n",
    "    pool = ThreadPool(multiprocessing.cpu_count()-1)\n",
    "    pool.starmap(dwnld,zip(enumerate(new_results),itertools.repeat(genre)))\n",
    "    pool.close\n",
    "    pool.close()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    for (a,b) in genres:\n",
    "        if not os.path.exists(\"./\"+a):\n",
    "            os.mkdir(a)\n",
    "        for_genre(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
